#!/usr/bin/env python3
import argparse
from difflib import context_diff
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import statsmodels.api as sm
from sklearn.linear_model import LinearRegression
from scipy.stats import pearsonr
from scipy.ndimage import gaussian_filter1d
from scipy.signal import argrelextrema
from sea_ice_phenology.utils import interQuantileMask

pd.options.mode.chained_assignment = None
lowess = sm.nonparametric.lowess


def hampel_filter(input_series, window_size, n_sigmas=3):
    """
    By Eryk Lewinson: https://towardsdatascience.com/outlier-detection-with-hampel-filter-85ddf523c73d
    """

    n = len(input_series)
    new_series = input_series.copy()
    k = 1.4826  # scale factor for Gaussian distribution

    indices = []

    # possibly use np.nanmedian
    for i in range((window_size), (n - window_size)):
        x0 = np.median(input_series[(i - window_size) : (i + window_size)])
        S0 = k * np.median(
            np.abs(input_series[(i - window_size) : (i + window_size)] - x0)
        )
        if np.abs(input_series[i] - x0) > n_sigmas * S0:
            new_series[i] = x0
            indices.append(i)

    return new_series, indices


def melt_freeze_season(dataframe, band):
    dataframe["freeze_melt"] = dataframe[band].copy()

    upper_thresh = (
        max(dataframe["freeze_melt"]) - min(dataframe["freeze_melt"])
    ) * 0.7 + min(dataframe["freeze_melt"])
    lower_thresh = (
        max(dataframe["freeze_melt"]) - min(dataframe["freeze_melt"])
    ) * 0.1 + min(dataframe["freeze_melt"])
    dataframe["freeze_melt"].mask(
        dataframe["freeze_melt"] < lower_thresh, -3, inplace=True
    )
    dataframe["freeze_melt"].mask(
        (dataframe["freeze_melt"] > lower_thresh)
        & (dataframe["freeze_melt"] < upper_thresh),
        0,
        inplace=True,
    )
    dataframe["freeze_melt"].mask(
        dataframe["freeze_melt"] > upper_thresh, 3, inplace=True
    )


def coefficient_method(dataframe, band):
    # Hampel Filtering
    sequence, _ = hampel_filter(dataframe[band], 9, n_sigmas=1)
    # Lowess Filtering
    sequence = pd.Series(
        lowess(
            exog=sequence.index.astype(int),
            endog=sequence,
            return_sorted=False,
            frac=5 / len(sequence),
        )
    )

    subset_length = 30
    anomaly_li = [0 for _ in range(subset_length)]
    idx = subset_length
    while idx < dataframe.shape[0]:
        subset_1 = sequence[idx - subset_length : idx].dropna()
        subset_2 = sequence[idx : idx + subset_length].dropna()
        notna_1 = sequence[idx - subset_length : idx].notna()
        index_1 = notna_1[notna_1].index.astype(np.int64)
        notna_2 = sequence[idx : idx + subset_length].notna()
        index_2 = notna_2[notna_2].index.astype(np.int64)

        if (
            subset_1.shape[0] > 2 * subset_length // 3
            and subset_2.shape[0] > 2 * subset_length // 3
        ):
            reg_1 = (
                LinearRegression()
                .fit(np.array([subset_1.index]).reshape(-1, 1), subset_1)
                .coef_[0]
            )
            reg_2 = (
                LinearRegression()
                .fit(np.array([subset_2.index]).reshape(-1, 1), subset_2)
                .coef_[0]
            )
            r1, _ = pearsonr(index_1, subset_1)
            r2, _ = pearsonr(index_2, subset_2)

            anomaly_li.append(reg_1 * r1 - reg_2 * r2)
        else:
            anomaly_li.append(0)

        idx += 1

    tmp = dataframe.copy()
    tmp["anomaly"] = anomaly_li

    maxima = argrelextrema(tmp["anomaly"].to_numpy(), np.greater, order=30)
    minima = argrelextrema(tmp["anomaly"].to_numpy(), np.less, order=30)
    tmp["maxima"] = [1 if i in maxima[0] else 0 for i in range(len(tmp))]
    tmp["minima"] = [1 if i in minima[0] else 0 for i in range(len(tmp))]

    tmp["anomaly"] = interQuantileMask(tmp["anomaly"], low=-1, middle=0, high=1)

    # Divide timeseries into freezing, transition and melt seasons
    melt_freeze_season(tmp, band)

    # Detect dates with high probability of phenology
    tmp["phenology"] = (
        tmp["anomaly"] * tmp["maxima"]
        + tmp["anomaly"] * tmp["minima"]
        + tmp["freeze_melt"]
    )
    tmp["phenology"].mask(tmp["phenology"] == 3, 0, inplace=True)
    tmp["phenology"].mask(tmp["phenology"] == -3, 0, inplace=True)

    return tmp["phenology"]


def three_day_method(dataframe, band):
    # Hampel Filtering
    sequence, _ = hampel_filter(dataframe[band], 9, n_sigmas=1)
    # Lowess Filtering
    sequence = lowess(
        exog=sequence.index.astype(int),
        endog=sequence,
        return_sorted=False,
        frac=5 / len(sequence),
    )

    anomaly_li = [0 for _ in range(dataframe.shape[0])]

    for idx, val in enumerate(sequence):
        try:
            first = val - sequence[idx + 1]
            second = sequence[idx + 1] - sequence[idx + 2]
            third = sequence[idx + 2] - sequence[idx + 3]
        except IndexError:
            continue

        if (first < 0 and second < 0 and third < 0) or (
            first > 0 and second > 0 and third > 0
        ):
            anomaly_li[idx] = first + second + third

    tmp = dataframe.copy()
    tmp["anomaly"] = anomaly_li
    pd.set_option("display.max_rows", None)
    tmp["anomaly"] = interQuantileMask(tmp["anomaly"], low=-1, middle=0, high=1)

    # Divide timeseries into freezing, transition and melt seasons
    melt_freeze_season(tmp, band)

    # Detect dates with high probability of phenology
    tmp["phenology"] = tmp["anomaly"] + tmp["freeze_melt"]
    tmp["phenology"].mask(tmp["phenology"] == 3, 0, inplace=True)
    tmp["phenology"].mask(tmp["phenology"] == -3, 0, inplace=True)

    return tmp["phenology"]


def main(args):
    ts_df = pd.read_csv(args.input, thousands=",")
    ts_df["system:time_start"] = pd.to_datetime(ts_df["system:time_start"])
    ts_df = ts_df.groupby("system:time_start").mean()

    for band in ts_df.columns:
        if band.endswith("interpolate") == False:
            continue

        tmp = ts_df.copy()
        tmp["Date"] = tmp.index

        if args.type == "coefficient":
            tmp["phenology"] = coefficient_method(tmp, band)
        elif args.type == "three-day":
            tmp["phenology"] = three_day_method(tmp, band)

        # Maker for plotting
        tmp["marker"] = tmp["phenology"].abs()
        tmp["marker"].mask(tmp["marker"] > 0, "Phenology", inplace=True)
        tmp["marker"].mask(tmp["marker"] == 0, "", inplace=True)

        # Define names for phenology
        tmp["phenology"].mask(tmp["phenology"] == 0, "", inplace=True)
        tmp["phenology"].mask(tmp["phenology"] == 4, "FU", inplace=True)
        tmp["phenology"].mask(tmp["phenology"] == 2, "MO", inplace=True)
        tmp["phenology"].mask(tmp["phenology"] == 1, "PO", inplace=True)
        tmp["phenology"].mask(tmp["phenology"] == -1, "PD", inplace=True)
        tmp["phenology"].mask(tmp["phenology"] == -2, "OW", inplace=True)
        tmp["phenology"].mask(tmp["phenology"] == -4, "FO", inplace=True)

        sns.set_style("dark")
        _, _ = plt.subplots(figsize=(20, 4))

        sns.scatterplot(
            data=tmp,
            x="Date",
            y=band,
            hue="phenology",
            palette="tab10",
            size="marker",
            sizes=(30, 5),
        )

        plt.grid()
        plt.show()

        ts_df[f"{band}_phenology"] = tmp["phenology"]

    ts_df.to_csv(f"{'.'.join(args.input.split('.')[:-1])}_phenology.csv")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--input",
        type=str,
        help="Path to time-series data file (csv)",
        required=True,
    )
    parser.add_argument(
        "--type",
        type=str,
        choices=["coefficient", "three-day"],
        default="coefficient",
        help="Phenology detection method",
    )

    args = parser.parse_args()

    main(args)
